{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "num_classes = 3\n",
    "\n",
    "def load_data(data_path, class_dir_names):\n",
    "    imgs = []\n",
    "    targs = []\n",
    "    \n",
    "    for c, class_dir_name in enumerate(class_dir_names):\n",
    "        path = \"{}/{}\".format(data_path, class_dir_name)\n",
    "        files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        \n",
    "        for filename in files:\n",
    "            if filename[0] == \".\":\n",
    "                continue\n",
    "            img_path = \"{}/{}\".format(path, filename)\n",
    "            img = cv2.imread(img_path)[:,:,0]\n",
    "            img = np.array(img, dtype=np.float64).reshape([img_rows, img_cols, 1])\n",
    "            img /= 255\n",
    "            img -= 0.5\n",
    "            \n",
    "            for i in range(20):\n",
    "                distort = img.copy() + np.random.randn(img.shape[0], img.shape[1], 1) * .01\n",
    "                if np.random.randint(2):\n",
    "                    distort = np.flipud(distort)\n",
    "                if np.random.randint(2):\n",
    "                    distort = np.fliplr(distort)\n",
    "                imgs.append(distort)\n",
    "                targs.append(c)\n",
    "    \n",
    "    targs = np.array(targs)\n",
    "    targs = keras.utils.to_categorical(targs, num_classes=num_classes)\n",
    "        \n",
    "    return (np.array(imgs), targs)\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "#x_train = np.random.randn(10,img_rows,img_cols,1)\n",
    "#y_train = np.random.randint(0, 2, size=(10,1))\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes) # one hot\n",
    "\n",
    "class_names = [\"b\", \"x\", \"o\"]\n",
    "x_train, y_train = load_data(\"data\", class_names)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRFHwC5Eo/wdxMxM+VFFj9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125917400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ri = np.random.randint(x_train.shape[0])\n",
    "plt.imshow(np.resize(x_train[ri], (img_rows, img_cols)), cmap=plt.cm.gray)\n",
    "print(y_train[ri])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(4, 4),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(8, kernel_size=(4, 4), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19080/19080 [==============================] - 14s - loss: 0.2872 - acc: 0.8850    \n",
      "Epoch 2/10\n",
      "19080/19080 [==============================] - 15s - loss: 0.1204 - acc: 0.9548    \n",
      "Epoch 3/10\n",
      " 8208/19080 [===========>..................] - ETA: 9s - loss: 0.0949 - acc: 0.9653"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-c2cd93630ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-03cdf0b64876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mshow_webcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-03cdf0b64876>\u001b[0m in \u001b[0;36mshow_webcam\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/x/x_{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mimg_indx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m# save the img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/o/o_{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use to collect training data and see predictions for an individual patch\n",
    "def show_webcam():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    img_indx = 0\n",
    "    while True:\n",
    "        ret_val, img = cam.read()\n",
    "        \n",
    "        img = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
    "        \n",
    "        img = img[:img_rows,:img_cols,0]\n",
    "        img = cv2.flip(img, 1)\n",
    "        \n",
    "        cv2.imshow('my webcam', cv2.resize(img,(256,256)))\n",
    "        \n",
    "        img_pred = img.astype(np.float64).reshape(1, img_rows, img_cols, 1)\n",
    "        img_pred /= 255\n",
    "        img_pred -= 0.5\n",
    "        \n",
    "        max_class = np.argmax(model.predict(img_pred)[0])\n",
    "        print(class_names[max_class])\n",
    "        clear_output(wait=True)\n",
    "        if cv2.waitKey(1) == 27: \n",
    "            break  # esc to quit\n",
    "        \n",
    "        img_indx = np.random.randint(10000)\n",
    "        if cv2.waitKey(33) == ord('x'):\n",
    "            # save the img\n",
    "            cv2.imwrite(\"./data/x/x_{}.png\".format(img_indx), img)\n",
    "            img_indx += 1\n",
    "        if cv2.waitKey(33) == ord('o'):\n",
    "            # save the img\n",
    "            cv2.imwrite(\"./data/o/o_{}.png\".format(img_indx), img)\n",
    "            img_indx += 1\n",
    "        if cv2.waitKey(33) == ord('b'):\n",
    "            # save the img\n",
    "            cv2.imwrite(\"./data/b/b_{}.png\".format(img_indx), img)\n",
    "            img_indx += 1\n",
    "        \n",
    "            \n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "show_webcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-48f90edc4810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mshow_over_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-182-48f90edc4810>\u001b[0m in \u001b[0;36mshow_over_image\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mimg_pred\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mclass_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mmax_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1594\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# scan over entire image coloring where the classes are\n",
    "\n",
    "def show_over_image():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    img_indx = 0\n",
    "    \n",
    "    while True:\n",
    "        ret_val, img = cam.read()\n",
    "        img = img[:,:img.shape[0]]\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (int(img.shape[1]/4), int(img.shape[0]/4)))\n",
    "        img = cv2.flip(img, 1)\n",
    "        \n",
    "        img_out = img.copy()\n",
    "        \n",
    "        for i in range(100):\n",
    "            \n",
    "            r = np.random.randint(img.shape[0]-img_rows)\n",
    "            c = np.random.randint(img.shape[1]-img_cols)\n",
    "            \n",
    "            img_pred = img[r:r+img_rows, c:c+img_cols, 0]\n",
    "            img_pred = img_pred.astype(np.float64).reshape(1, img_rows, img_cols, 1)\n",
    "            img_pred /= 255\n",
    "            img_pred -= 0.5\n",
    "\n",
    "            class_dist = model.predict(img_pred)[0]\n",
    "            max_class = np.argmax(class_dist)\n",
    "\n",
    "            cindex = -1\n",
    "            if class_dist[1] > .96:\n",
    "                # xs\n",
    "                cindex = 0\n",
    "            elif class_dist[2] > .96:\n",
    "                # os\n",
    "                cindex = 2\n",
    "\n",
    "            if cindex != -1:\n",
    "                img_out[r:r+img_rows, c:c+img_cols, cindex] = 1\n",
    "\n",
    "            #print(class_names[max_class])\n",
    "            #clear_output(wait=True)\n",
    "                \n",
    "        cv2.imshow('tic tac', cv2.resize(img_out, (512, 512)))\n",
    "                \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break  # esc to quit\n",
    "            \n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "show_over_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
